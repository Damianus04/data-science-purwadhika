- Interpreter programming language -> program akan langsung mengeksekusi setiap baris kode dari atas ke bawah
- case sensitive -> "A" beda dengan "a"
- tidak butuh semicolon
- Tabulasi - indentasi


Materi Exam Modul 1
- mengkonversi persamaan matematika dalam algoritma dengan variabel


MONGODB

--> Install MongoDB for community
1. buat folder baru dulu di C --> data\db
2. cmd pertama - server: C:\Program Files\MongoDB\Server\4.4\bin>mongod --dbpath C:\data\db
3. cmd kedua - execution: C:\Program Files\MongoDB\Server\4.4\bin>mongo

show database
- show dbs

use/create database
- use database_name

delete database
- use database_name
- db.dropDatabase()

show collections
- show collections

create collections
- db.createCollections('karyawan')

show data on collections
-db.Aset.find()

-> with condition
db.Employee.find({'Usia': 25})
db.Employee.find({'Gaji': 20000000}).pretty()

-> conditional
db.Employee.find({$and: [{}, {}]})
--> db.Employee.find({$and: [{"Nama": "Rosi"}, {"Gaji": 15000000}]})
--> db.Employee.find({$or: [{"Nama": "Joni"}, {"Kota": "Jakarta"}]})
--> db.Employee.find({"Usia": {$lt: 26}}) --> less than
--> db.Employee.find({"Usia": {$gt: 26}}) --> greater than
--> lte: less than equal, gte: greater than equal
--> db.Employee.find().limit(4).skip(3)

-> sort
--> db.Employee.find().sort({"Gaji": 1}) --> ascending
--> db.Employee.find().sort({"Gaji": -1}) --> descending

-> count
--> db.Employee.find().count()
--> db.Employee.find({"Nama": "Andre"}).count()

add data to Collections
db.Employee.insert([
... {"Nama": "Yogi", "Usia": 30, "Kota": "Malang", "Gaji": 16000000},
... {"Nama": "Cecil", "Usia": 26, "Kota": "Bandung", "Gaji": 15000000},
... {"Nama": "Andre", "Usia": 27, "Kota": "Jakarta", "Gaji": 17000000},
... {"Nama": "Andi", "Usia": 28, "Kota": "Bandung", "Gaji": 25000000}
... ])
--> if single data, [] not used

update data value in Collections
- update all --> db.Employee.update({}, {$set: {"Dept": "Data"})
- update per item --> db.Employee.update({"Nama": "Mike"}, {$set: {"Usia": 25} })

update data key in Collections
- update all --> db.Employee.updateMany({}, {$set: {"Dept": "Data"}})
	     --> db.Employee.updateMany({}, {$rename: {"Dept": "Divisi"}})
- update per item --> db.Employee.update({"Nama": "Mike"}, {$rename: {"Usia": "Umur"}})

update data based on certain query
- db.Employee.updateMany({'Nama': 'Rosi'}, {$rename: {"Usia": "Umur"}}

remove data
-  db.Aset.remove({"nama": "brankas"})db.

remove data key and value
- db.Employee.update({"Nama": "Mike"}, {$unset: {"Umur": true}})

import new data
- C:\Program Files\MongoDB\Tools\100\bin>mongoimport --db Culinary --collection restaurants --file restaurants.json
- make sure the .json file is copied to the directory

create user
1. go to one of db and collection
2. > db.createUser({
... 'user': 'AdministratorDB',
... 'pwd': 'Admin123',
... 'roles': ['dbAdmin', 'readWrite']
... })

3. show users or db.getUsers to show the information


MongoDB exercise: 
1) https://www.w3resource.com/mongodb-exercises/

2) versi >4.4 install mongodb tools (https://www.mongodb.com/try/download/database-tools?tck=docs_databasetools)

3) masuk ke hasil instalasi (C:\Program Files\MongoDB\Tools\100\bin>mongoimport --db NamaDBS --collection DataRESTO --file restaurants.json
{
  "address": {
     "building": "1007",
     "coord": [ -73.856077, 40.848447 ],
     "street": "Morris Park Ave",
     "zipcode": "10462"
  },
  "borough": "Bronx",
  "cuisine": "Bakery",
  "grades": [
     { "date": { "$date": 1393804800000 }, "grade": "A", "score": 2 },
     { "date": { "$date": 1378857600000 }, "grade": "A", "score": 6 },
     { "date": { "$date": 1358985600000 }, "grade": "A", "score": 10 },
     { "date": { "$date": 1322006400000 }, "grade": "A", "score": 9 },
     { "date": { "$date": 1299715200000 }, "grade": "B", "score": 14 }
  ],
  "name": "Morris Park Bake Shop",
  "restaurant_id": "30075445"
}


MySQL
Client - 3 alternatif
1. melalui GUI
2. melalui mySQL command line client
3. melalui command prompt

--> melalui command prompt
	- cd C:\Program Files\MySQL\MySQL Server 8.0\bin
	- --> mysql -u damianus -p

Reconnect localhost
1. Win+R
2. run services.msc
3. find MySQL 80 
4. click start

SELECT COUNT(DISTINCT --) AS -- FROM --
GROUP BY --
WHERE/HAVING --
ORDER BY -- 
LIMIT --




JOIN
INNER JOIN akan sama saja yaitu hanya mengambil irisan
kuncinya ada di posisi setelah/sebelum RIGHT atau LEFT
-- --- -- INNER JOIN
-- --- -- menampilkan hasil irisan yang sama-sama ada di kedua table
-- SELECT students.student_name, lecturers.lecturer_name --> nama table/kolom sesuai DB
-- FROM lecturers INNER JOIN students 		         --> dibalik sama aja
-- ON students.lecturer_id = lecturers.lecturer_id;      --> dibalik sama aja


-- --- -- LEFT JOIN
-- --- -- semua data di table sebelum operator LEFT JOIN akan muncul
-- --- -- tampilan data tergantung kolom mana yang akan dipilih lebih dulu dalam SELECT

-- --- -- sama2 left join tapi dituker hasilnya beda
-- SELECT L.lecturer_name, S.student_name 
-- FROM lecturers L LEFT JOIN students S 
-- ON L.lecturer_id = S.lecturer_id;

-- SELECT lecturers.lecturer_name, students.student_name
-- FROM students LEFT JOIN lecturers						-- > ketika ditukar hasilnya beda
-- ON lecturers.lecturer_id = students.lecturer_id			-- > id ketika ditukar tidak memberikan efek


-- --- -- RIGHT JOIN
-- --- -- semua data di table setelah operator RIGHT JOIN akan muncul
-- SELECT L.lecturer_name, S.student_name
-- FROM lecturers L RIGHT JOIN students S
-- ON L.lecturer_id = S.lecturer_id;

-- SELECT lecturers.lecturer_name, students.student_name
-- FROM lecturers RIGHT JOIN  students
-- ON students.lecturer_id = lecturers.lecturer_id



FINAL PROJECT:
1. Problem
2. Goals
3. Perusahaan - user
4. Data
5. Past Projects
	- Credit Scoring - SBA Loan Default Prediction
	- Sentiment Analysis - Twitter
	- Income Prediction
	- New Credit Card Application Prediction
	- Employee Turn-Over
	- Salary Prediction - NBA Salary Prediction
	- Heart Disease Prediction
	- Restaurant Recommendation


EVALUATION METRICS
- Linear Regression
	- persamaan garis y = ax + b
	- trend garis akan mendekati data prediksi jika a dan b
	  memiliki angka yang mendekati sempurna
	- kombinasi loss curve a dan b menghasilkan parabola 3D
	- untuk mencari a dan b, maka digunakan loss optimizer
	- ada dua jenis -> gradient & non-gradient descent

	- dengan teknik gradient descent, a dan b dapat dicari dengan
	  mencari titik paling rendah (menuruni bukit)
	- di linear regression, bukit cuma satu

- Polynomial Regression
	- menambahkan kuadrat untuk membuat garis/prediksi berlekuk
	- pangkat 1: lurus, pangkat 2: lengkung,
	  pangkat 3 dst: mulai berlekuk/bergelombang

- Bias-Variance Tradeoff
	- Bias = Loss = Error
	- Variance = variasi lekukan garis/prediksi
	- More complex model (high variance) ->prone to overfit (low bias)
	  More simple model(low variance) -> prone to underfit (high bias)
	- tidak ada yang high variance dan high bias dan
	  tidak ada yang low variance dan low bias
	  jika ada maka model itu sudah pasti salah dan 
	  lebih jelek dari nilai rata2
	- model yang ideal adalah medium variance dan medium bias




EDA 
-> EDA harus mengelaborasi data secara tuntas dan kompleks
-> Machine Learning tahap awal harus sesimple mungkin utk set benchmark

	step-step EDA
	1. import data
		- pd.read_csv('file_name', index_col=0/'column_name')
	2. overview info
		- df.describe() --> numeric stats
		- data_desc = desc(df)
	3. set the EDA using crosstab/pivot_table
		
	4. set the visualization based on EDA on no. 3
	- Histogram - matplotlib
	  - to see the data distribution - one variable
	  -----------------------
	  plt.style.use('seaborn')
	  fig = plt.figure(figsize=(8,6))
	  ax = plt.axes()

	  ax.hist(df.price)
	  ax.set_title('Distribution of Price')
	  ax.set_xlabel('price')
	  ax.set_ylabel('frequency')

	  plt.show()
	  -----------------------

	- Histogram - seaborn
	  #######################
	  sns.distplot(data_perfume_moist.price)
	  plt.title('Distribution of Price for Perfume & Moisturizers')

	  plt.xlabel('price')
	  plt.ylabel('frequency')

	  plt.show()
	  #######################

	- Piechart - matplotlib
	  - to find the categorization
	  =======================
	  1) grouping
	     price_by_price_category = data_perfume_moist[[
		'price', 
		'price_category']].groupby(['price_category'], 
		as_index=False).count()
	      
	     price_by_price_category

	  2) create pie chart
	     # Pie Chart
	     fig = plt.figure(figsize=(9,7))
	     ax = plt.axes()

	     # data
	     ax.pie(price_by_price_category['price'], 
		labels = price_by_price_category['price_category'], 
		explode = (0, 0.05, 0.05, 0.4, 0, 0))

	     # data label
	     ax.set_title('Price Category: Perfume & Moisturizer', size=16)
	     ax.axis('equal')

	     # show
	     plt.show()
	 =======================
	
	- Scatterplot - matplotlib
	  - to find pattern and correlation
	 #######################
	    # figure & axis
	    fig = plt.figure(figsize=(8,6))
	    ax = plt.axes()

	    # data
	    total_bill = tips['total_bill']
	    tip = tips['tip']

  	    ax.scatter(total_bill, tip)

       	    # data label
	    plt.title('Scatter Plot: Total Bill vs Tip', size=15)
	    plt.xlabel('Total Bill')
	    plt.ylabel('Tip')

	    # show
	    plt.show()
	#######################

	- Boxplot - seaborn
	  - to compare the data distribution
	  sns.boxplot(data=df, x='brand', y='price')

	- Barplot - matplotlib
	***********************
	 1) group first
	  review_by_category = df_top_5[df_top_5.brand=='tarte'][['number_of_reviews', 'category']].groupby(['category'], as_index=True).sum()
	  # review_by_category

	 2) visualize
	  # figure & axis
	  fig = plt.figure(figsize=(8,6))
 	  ax = plt.axes()

 	  # data
	  category = df_top_5[df_top_5.brand=='tarte']['category'].unique().tolist()
	  number_of_reviews = review_by_category['number_of_reviews']

	  ax.barh(category, number_of_reviews)

	  # data label
	  plt.title('Review based on Category', size=15)
	  plt.xlabel('Number of Reviews')
	  plt.ylabel('Category')

	  # show
	  plt.show()
	***********************


PLOTLY
# Boxplot with plotly
# if filtered used data = df_top_5[df_top_5.brand=='tarte']
fig = px.box(df_top_5, x='brand', y='price')
fig.show()


# Barplot with plotly
data = df_top_5[df_top_5.brand=='tarte']
fig = px.bar(data, x='category', y='number_of_reviews')
fig.show()


# Scatterplot with plotly
data = df_top_5[df_top_5.brand=='tarte']
fig = px.scatter(data, x='price', y='number_of_reviews')
fig.show()


==> appendix
= def desc(df):
    dataDesc = []

    for i in df.columns:
        dataDesc.append([
            i,
            df[i].dtypes,
            df[i].isna().sum(),
            round((((df[i].isna().sum()) / len(df)) * 100), 2),
            df[i].nunique(),
            df[i].drop_duplicates().sample(2).values
        ])

    description = pd.DataFrame(dataDesc, columns=[
        'Data Feature',
        'Data Types',
        'Null',
        'Null Percentage',
        'Unique',
        'Unique Sample'
    ])

    return description


pandas'question:
1) memberi nama kolom pada dataframe value_counts
2) membuat multi column baru dengan .apply()
3) convert day using .map()



Visualisasi
- untuk sendiri
- untuk dipresent: melihat hubungan antara independent dan dependen variable



FINAL PROJECTS
1. Statistics

- Standard Deviation - untuk menunjukkan keragaman data
- Variance -> pangkat 2 dari standard deviation
- Mean, Median, Quartile formula
  - quartile -> pertama tahu nilai tengah dulu (median) setelah diurutkan
	- 
- Boxplot -> 1.5 IQR
	- model2 boxplot
	- IQR: Q3-Q1 (nilai tengah antara median dan nilai maksimum)

- Correlation - mengetahui hubungan dari dua variable.
  1. korelasi range nya antara -1 sampai 1, korelasi itu kuat
     (mendekati 1/-1) dan lemah (mendekati 0)
  2. korelasi positif mendekati 1, korelasi negatif mendekati -1
- korelasi ada - Pearson dan Spearman

2. Business understanding & Machine learning

3. Final Projects Concept
	- Vitamin - to boost the performance - to improve/optimize
	- Medicine - to cure the illness - to solve problem
4. Modul 2 - Exam
	- PyMySQL
	- EDA & Visualization
	- Dashboard
   
	referensi test
	1) EDA & Visualization

	2) SQL



MACHINE LEARNING
- Analogi ML --> anak yang dibawa ke taman untuk belajar banyak hal mengenali benda-benda yang baru maupun lama.
- Analogi ML Supervised --> 
	- di sekolah ada murid
	- mau mengirim murid ke olimpiade matematika
	- cara seleksi? ambil sampel untuk ambil murid paling pinter
	- terpilih murid A, B, C lalu diberi materi sampai pinter
	- ketika di fase akhir, mereka diberi ujian untuk menentukan siapa ikut olimpiade
	- setelah test, murid B paling bagus dan ikut olimpiade dengan bekal, 
	  semua latihan + jawaban (training) dan test + jawaban (testing).

	- data scientist ==> sekolah
	- model + algoritma ==> murid
	- deploy model + algoritma ==> olimpiade
	- training + testing ==> soal latihan dan test kelulusan olimpiade

- Classification ada ground truth (supervised)
  Clustering tidak punya ground truth (unsupervised)


- numerik: interval (median, mean) & ratio
  kategorik: nominal(tidak punya urutan: warna) & ordinal(punya urutan: jenjang pend)

- data adalah bagian terpenting dari machine learning.
  seberapa bagus algoritmanya, jika datanya jelek, maka hasilnya jelek.

- x/feature/independent variable/explanatory
  y/label/dependent variable/response
	--> label muncul setelah feature

- normality test untuk melihat potensi fillna

STATISTIK 
Parameter: angka yang mewakili data dari suatu populasi
Statistik: angka yang mewakili data dari suatu sample
Di Statistika, yang kita periksa dinamakan variabel
	--> variabel: karakter yg dapat diukur, dihitung dan dikelompokkan (tinggi, berat, warna, etc)
		dapat bervariasi satu sama lain


TENDENSI SENTRAL, UKURAN DISPERSI, UKURAN LOKASI
1. tendensi sentral -> angka yang mewakili kondisi secara keseluruhan data
2. ukuran dispersi -> sebaran data
3. ukuran posisi -> dimana posisi data tunggal kita dalam distribusi data scr keseluruhan

1) Tendensi Sentral
	- Mean (data dlm interval/rasio), Median (data dlm skala ordinal), Modus (data dlm skala nominal)
	- Mean sensitif terhadap outlier, jika begitu maka bisa diganti ke median
	- Jika data terdistribusi normal, maka hasil modus hampir sama dengan mean/median
	- Jika modus dalam data lebih dari satu, maka grafiknya bisa bimodal/multimodal, jika hanya satu namanya unimodal

2) Dispersi
	- Rentang: paling sederhana dan paling kurang kuat; menggunakan max dan min data
	- Varians: variasi dari data; 
		- cara hitung: rerata dari selisih kuadrat masing2 skor terhadap mean
			a. hitung mean dari seluruh data
			b. setiap item data dikurangi mean lalu dikuadratkan
			c. jumlahkan hasilnya dan hitung reratanya
	- Standard Deviation: 
	       - rerata jarak skor terhadap mean yang digunakan untuk mengukur dispersi skor terhadap rerata
	       - hasil penjumlahannya sama dengan nol
	       - semakin besar std, maka semakin besar data tersebar
	       - data yang bagus adalah yang std nya tidak terlalu besar
	       - cara hitung: akar kuadrat dari varians
	- Standard Error:
	       - SE = Standard Error of the Mean (SEM)
	       - SE = SD dibagi akar banyaknya pengamatan (akar n)
	      
3) Ukuran Posisi
	- Kuartil: data dibagi jadi 4 bagian sama (Q1, Q2, Q3), Q2=Median
	- Desil: data dibagi jadi 10 bagian sama, D5=Median
	- Persentil: data dibagi menjadi 100 bagian sama, P50=Median
	     

Istilah dalam EDA Statistik:
- n -> jumlah subjek dalam kelompok
- N -> jumlah total subjek
- M -> Mean
- Mdn -> Median
- SD -> Standard Deviation


JENIS STATISTIK
--> Deskriptif
	- menggambarkan karakteristik
	- mendeskripsikan/menggambarkan kondisi data (sampel/populasi)
	- hasil analisa tidak bisa dipakai untuk generalisasi pada populasi
--> Inferensia
	- memberikan analisis yang lebih dalam
	- ingin memprediksi/menggambarkan kondisi populasi berdasarkan data dari sample.
	- hasil analisa bisa untuk generalisasi pada tingkat populasi


AKTIVITAS UTAMA
1) Estimasi - menduga parameter populasi berdasarkan statistik (std, mean, etc) dari sample.
	- estimasi titik (satu nilai tunggal)
	- estimasi interval (rentangan nilai)

2) Uji Hipotesis - memiliki dugaan thd parameter populasi; kita memiliki prediksi dari kondisi populasi lalu kita uji dugaan tersebut bisa diterima atau ditolak.
	- hipotesis nol		--> menyatakan tidak ada hubungan
	- hipotesis alternatif	--> menyatakan ada hubungan

	hasil akhirnya hanya salah satu hipotesis yang diterima


JENIS HIPOTESIS (1:50:00/20210210-Linear Regression)
1) Hipotesis Statistik
	a) Ho    -> u1 = u2 - tidak ada hubungan/tidak ada perbedan
	b) Ha/H1 -> u1 != u2 - ada hubungan/ada perbedaan
2) Hipotesis Penelitian
	a) observasi dari suatu kondisi
	b) menemukan ada permasalahan
	c) dirumuskan dalam pertanyaan penelitian
	d) ada jawaban sementara (hipotesis penelitian) berdasarkan dari kajian pustaka, referensi ilmiah dari sumber yang sudah ada.
	f) setelah merumuskan hipotesis penelitian kita lalu menentukan hipotesis statistik
	g) ada Ho dan Ha
	h) setelah ada hipotesis statistik maka saat nya melakukan uji statistik untuk menentukan mana yang dapat diterima (Ho atau Ha)


	hipotesis penelitian sejalan dengan hipotesis alternatif:  menyatakan ada hubungan.
	kadang hipotesis penelitian bisa sejalan dengan hipotesis nol


UJI STATISTIK
yang dijadikan dasar awal uji statistik adalah Ho
1) Menolak Ho		-> Ho tidak dapat diterima
2) Gagal Menolak Ho	-> Ho dapat diterima


	
SKALA PENGUKURAN
NOIR = Nominal Ordinal Interval Ratio: semakin ke kanan semakin presisi
	NO: categoric
	IR: numeric

Karakter Penanda
1. Identitas: setiap nilai pada skala pengukuran bersifat unik
2. Besaran: nilai memiliki hubungan teratur satu sama lain.
3. Interval yang sama: jarak antar skala sama
4. Nol mutlak: memiliki titik nol yang sebenarnya, angka nol sebagai angka paling kecil, tidak ada minus

1) Skala Nominal -> memenuhi Identitas
	- skala paling lemah/rendah
	- hanya bisa membedakan antar benda/peristiwa berdasarkan nama (predikat)
	- angka/simbol tidak ada arti kuantitatif, hanya menunjukkan ada/tidak ada nya karakteristik
	- analisa statistika terbatas: hanya alat ukur non-parametrik (modus, distribusi frekuensi, chi-square)
	- tidak bisa diterapkan operasi matematika standar
	- contoh: jenis kelamin (Pria/1, Wanita/2)
2) Skala Nominal -> memenuhi Identitas, Besaran
	- nilai hasil pengukuran selain menunjukkan perbedaan juga menunjukkan urutan/tingkatan objek yang diukur
	- meski nilai sudah memiliki batas yang jelas tapi belum punya jarak
	- analisa statistika terbatas: hanya alat ukur non-parametrik (modus, distribusi frekuensi, chi-square)
	- tidak bisa diterapkan operasi matematika standar
	- contoh: tingkat kesukaan dari level 1, 2, 3, 4, 5
	- contoh: juara kompetisi (1, 2, 3) -> 2x juara 1 tidak bisa dikatakan sama dengan juara 1
3) Skala Interval -> memenuhi Identitas, Besaran, Interval Sama
	- operasi arimatik dasar dapat diterapkan
	- sudah punya batas jelas dan jarak, tapi jarak itu belum merupakan kelipatan
	- contoh: suhu (selisih 20 ke 30 derajat sama dengan selisih 40 ke 50 derajat)
	- contoh: nilai ujian (A: 40, B: 80 -> tidak bisa dikatakan B dua kali lebih pintar dari A)
	- analisa statistika lebih beragam (ANOVA, uji T, ANCOVA)
4) Skala Rasio -> memenuhi Identitas, Besaran, Interval Sama, Nol Mutlak
	- skala rasio sama dengan interval hanya ditambah 0 mutlak
	- Nol mutlak = nilai yang paling rendah adalah nilai 0, tidak ada yang lebih rendah lagi
		- contoh: berat badan tidak mungkin kurang dari 0 kg
	- skala rasio sudah punya nilai perbandingan/rasio
		- contoh: A=20kg, B=40kg, B dua kali lebih berat dari A
	- operasi arimatik dasar dapat diterapkan
	- sudah punya batas jelas dan jarak yang merupakan kelipatan
	- contoh: 
	- analisa statistika lebih beragam (ANOVA, uji T, ANCOVA)



LINEAR REGRESSION
1) Basic Theory
- koefisien didapat dari rise/run, berapa naik nya untuk x dan y.
- intercept/titik potong didapat ketika x=0
- sehingga nanti akan terbentu y = a + bx + e--> y = (intercept) + (koef)x + (error)
	a = intercept = yang membuat nilai y pertama ketika x=0
	b = slope= slope& intercept dioperasikan bersama x untuk mendapatkan y selanjutnya, shg lama-lama akan terbentuk titik2 (garis)
	e = random error (jika ada)

- rumus umum ==> y = b0 + b1x + e
	--> a=b0=intercept=constanta, b=b1=slope/gradient=coeficient
	--> nilai e mempengaruhi seberapa dekat prediksi/regresinya dengan real value nya.
	--> semakin kecil e, semakin baik model regresinya
	--> b0 adalah nilai prediksi y ketika X=0
	--> b1 adalah perkiraan perubahan nilai ketika X berubah 1 unit/ukuran

- simple regression	: 1 independent variable
  multiple regression	: > 1 independent variable

- beta = slope/gradient

- 	gradient -> tingkat pengaruh/hubungan feature X terhadap dependent variable y; bisa mengukur tingkat signifikasi suatu feature dikaitkan dengan pearson
	intercept -> mayoritas kadang tidak dapat diinterpretasi

2) Estimating Coeficient (1:22:00/20210210-Linear Regression)
- Least Squares/SSE adl hasil jumlah dari error sum(yi-ypred)**2 garis yang melewati centroid hasil rata2 dari feature X & y.
- regresi tugasnya adalah mengecilkan SSE (Sum of Squared Error)
- regresi mencari garis yang SSE nya paling kecil
- iterasi regresi akan menghasilkan beberapa garis
- di antara banyak garis, garis yang memiliki SSE terkecil = best fit line
- kita bisa hitung coeficient/slope/gradient
	r * (sy/sx)
	--> r = pearson correlation
	--> sy = standard deviation y
	--> sx = standard deviation x
	--> koefisien 0 = tidak punya hubungan
	--> koefisien <0/>0 = ada hubungan
- interpretasi slope hanya bisa valid di rentang data yang saat itu dimiliki (feature X nya)

3) Estimating Intercept (only simple linear regression)
- y = mx + c
  c = yrata - mxrata

4) Interpretasi 
- yang keluar dari range data dianggap sudah tidak valid (1:40:00/20210210-Linear Regression)

- untuk lebih valid, maka lebih banyak sample harus dilibatkan.

5) HIPOTESIS TESTING adalah menjelaskan fenomena pada populasi hanya dengan menggunakan data sample yang kita punya saja.

- T-Test dan F-Test digunakan untuk cek uji hipotesis

5) Measuring prediction accuracy
- MSE = variance of residuals
- RMS = standard deviation of residuals.
- R square = ukuran kebaikan dari model prediksi.
- SSE adl hasil jumlah dari error sum(yi-ypred)**2 garis yang melewati centroid hasil rata2 dari feature X & y.
	- SSE = sum(yi - ypred)**2
- SST: - jika tidak punya variable independen untuk memprediksi harga rumah selanjutnya, garis linear terbaik adalah rata2 dari harga rumah itu sendiri
	- SST = sum(yi - yrata)**2
	- 
- SSR:  - selisih dari dua garis regresi (garis rata2 dan garis regresi terbaik dari sse)
	- SSR = sum(ypred - yrata)




- Korelasi pakai pearson (mengukur kekuatan relationship).
  Regresi untuk mencari dampak variable x ke Y.

- Multicolinearity -> hubungan antar independent variable
	--> expectation: antar independent variable tidak berhubungan

- jika data tidak normal, jika inferensial maka non parametrik test
  jika data normal, jika ingin inferensial maka pakai parametrik test

- populasi -> error
  sample -> residu

- Rsquare -> seberapa bagus garis linear yang dibanding yang pertama.

- misi regresi -> meminimalkan SSE hingga dapat garis paling error kecilnya.

- dalam linear regression untuk analisa, tidak boleh ada multicollinearity --> how to handle: dua variable independent yang saling mempengaruhi dirangkum jadi satu
- tapi untuk prediksi, multicollinearity boleh --> tapi konsekuensinya bisa ada overfitting

- sklearn.onehotencode -> pd.get_dummies

- success event di ML: contohnya dalam klasifikasi, 1 nya adalah churn, bad credit score





CONFUSION MATRIX
- accuracy bisa menipu, karena prediksi nya tidak sensitif terhadap data yang porsinya kecil.


KNN
- bagus ketika di scaling


DECISION TREE
- 
- gini impurity -> 
	- indeks penilaian, 
	- rumusnya menggunakan proba yes dan no
	- feature yang memiliki gini impurity paling kecil akan jd root pertama
	
- DT akan berhenti split jika
	- sudah mencapai max depth
	- sample habis
	- minimum sample split

tentukan parameter (leaf, max depth, dll)
feature nya dicari gini impurity nya, lalu diurutkan jadi tree
lalu tiap baris data nya baru dimasukkan ke logika tree nya


cara mengatasi - mau ga mau belajar, banyak resource, 








	
